%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the sample chapter file.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Author:   René Widmer
%           Institute for Surgical Technology and Biomechanics ISTB
%           University of Bern
%           rene.widmer@istb.unibe.ch
%
% Date:     10/28/2009
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Methods}
\section{Hecktor dataset}
For the segmentation model in this project, we utilized the dataset from the Hecktor Challenge 2022. This dataset consists of both training images with corresponding ground truth labels and test images without labels. For our purposes, we focused solely on the training subset due to the availability of ground truth annotations. This subset comprises 524 imaging cases collected from seven distinct clinical centers, including:

\begin{itemize}
    \setlength\itemsep{1pt}
    \setlength\parskip{0pt}
    \setlength\topsep{0pt}
    \item CHUM: Centre Hospitalier de l’Université de Montréal, Montréal, Canada
    \item CHUP: Centre Hospitalier Universitaire de Poitiers, France
    \item CHUS: Centre Hospitalier Universitaire de Sherbrooke, Sherbrooke, Canada
    \item CHUV: Centre Hospitalier Universitaire Vaudois, Switzerland
    \item HGJ: Hôpital Général Juif, Montréal, Canada
    \item HMR: Hôpital Maisonneuve-Rosemont, Montréal, Canada
    \item MDA: MD Anderson Cancer Center, Houston, Texas, USA
\end{itemize}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{images/repartition.PNG}
    \caption{Distribution of cases across sites}
\end{figure}
\newpage
Each case in the dataset contains two imaging modalities: computed tomography (CT), positron emission tomography (PET), and ground truth labels. The PET images were standardized using the Standardized Uptake Value (SUV). The CT and label images are provided in NIfTI format with a spatial resolution of 524 × 524 pixels in the axial plane, and variable depths across slices. While some CT images focus exclusively on the head and neck region, others encompass the entire body. In contrast, the PET images have a resolution of 128 × 128 pixels in the axial plane, with varying depths similar to the CT images.

\begin{figure}[ht]
    \centering
    \subfloat[CT Scan]{\includegraphics[width=0.3\textwidth]{images/CT_only.png}}\hfill
    \subfloat[PET Scan]{\includegraphics[width=0.3\textwidth]{images/PET_only.png}}\hfill
    \subfloat[CT + PET and label]{\includegraphics[width=0.3\textwidth]{images/ALL.png}}
    \caption{An example cases of the CHUP}
    \label{fig:three_subfigures}
\end{figure}
\newpage
\section{Segmentation model}

\subsection{Preprocessing}
The initial preprocessing step involved resampling the PET images to achieve uniform dimensions across modalities. Specifically, PET images were resampled to an axial plane resolution of
524×524 pixels. Some labels exhibited minor dimensional discrepancies, occasionally differing by one plane in either width or height. These discrepancies were rectified following the resampling process.
\vskip1em
Subsequently, after ensuring that all three imaging modalities (CT, PET, and label) were aligned to the same dimensions, the images were resampled to a common isotropic voxel size of 
1×1×1 mm. This resampling was performed to facilitate subsequent cropping of the head and neck region.
\vskip1em
For the cropping procedure, the center of the head was identified using the contours of the brain on the PET scan. Based on this central reference point, a subvolume of 
200×200×[maximum of 310 pixels] was extracted. This approach minimizes the computational burden associated with background regions devoid of ground truth information. Additionally, the images underwent normalization via z-score clipping to mitigate the effects of outliers.
\vskip1em
The processed images were saved in NIfTI format following the above steps. Further preprocessing techniques were applied during the training phase, which will be detailed in subsequent sections. Aspects of the preprocessing procedure were adapted from the methods employed by the winning team of the Hecktor Challenge 2022 \cite{Myronenko2023}
\begin{figure}[ht]
    \centering
    \subfloat[CT Scan]{\includegraphics[width=0.3\textwidth]{images/CT_ONLY_PP.png}}\hfill
    \subfloat[PET Scan]{\includegraphics[width=0.3\textwidth]{images/PET_ONLY_PP.png}}\hfill
    \subfloat[CT + PET and label]{\includegraphics[width=0.3\textwidth]{images/ALL_PP.png}}
    \caption{Same example cases after preprocessing}
    \label{fig:three_subfigures}
\end{figure}
\newpage
\subsection{Data augmentation}
During the training process, data augmentation was applied to the original images using the Medical Open Network for Artificial Intelligence (MONAI) framework. Spatial augmentations were applied to both imaging modalities, including random flipping, affine transformations (translation, rotation, and scaling). For the CT images, intensity augmentations were also incorporated, such as the addition of Gaussian noise, smoothing, contrast adjustment, and intensity shifting. All augmentations were applied with an occurence probability of 20\%.
\vskip1em
Following augmentation, the images were randomly cropped into patches of size 192×192×192 voxels. Patches were centered based on labels, with a 10\% probability of being centered on background, 45\% on primary tumors, and 45\% on nodal tumors. In cases where only one tumor type was present, the sampling probability for that tumor was increased to 90\%.
\vskip1em
For validation, a single patch of equal size was extracted, with a balanced distribution of 33\% for background, primary tumors, and nodal tumors. This approach eliminates the need for predictions using sliding windows (e.g., 8 predictions per image), as a single patch is used for each validation image of size 200×200×310.
\subsection{Model architectures}
The model used for segmentation is the Dynamic UNet (DynUNet) from MONAI. It provide several parameter to configure the model.
The architecture is represented below :
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{images/UNet.PNG}
    \caption{Model architecture}
    \label{fig:three_subfigures}
\end{figure}

The model operates in three dimensions, taking as inputs two modalities: computed tomography (CT) and positron emission tomography (PET). It produces three binary segmentation outputs: background, primary tumors, and nodal tumors.
\vskip1em
All convolutional kernels used in the model are of size 3×3×3. The architecture consists of six layers, with downsampling performed consistently by a factor of 2, reducing the input size from 192×192×192 to 6×6×6. Additionally, batch normalization is implemented in conjunction with residual blocks to enhance training stability and model performance.
The probabilites are then computed through softmax that incorporate the mutual exclusivity between the 3 segmentation masks.
\subsection{Training}
The training parameters for the model are as follows:
\begin{itemize}
    \setlength\itemsep{1pt}
    \setlength\parskip{0pt}
    \setlength\topsep{0pt}
    \item Optimizer : AdamW
    \item Learning rate : 1e-4
    \item Weight decay : 3e-5
    \item Batch size : 2
    \item Epochs : 100
\end{itemize}
A LambdaLR scheduler is employed, utilizing the following decay function:
\begin{equation}
    \text{Decay Factor} = \left(1 - \frac{\text{epoch}}{\text{number\_epoch}}\right)^{0.9}
\end{equation}
The loss function combines Dice loss and cross-entropy loss, defined as follows:
\begin{equation}
    \text{Dice Loss} = 1 - \frac{2 |P \cap Y|}{|P| + |Y|} \label{eq:dice_loss}
\end{equation}
\begin{equation}
    \text{Cross-Entropy Loss} = -\left(Y \log(P) + (1 - Y) \log(1 - P) \right) \label{eq:ce_loss}
\end{equation} 
where P is the prediction and Y is the ground truth.
\vskip1em
Dice loss is particularly advantageous for segmentation tasks involving imbalanced datasets, such as those found in head and neck tumor imaging, where the tumors are often significantly smaller than the surrounding tissues. The Dice coefficient, which Dice loss is based on, focuses on the overlap between the predicted segmentation and the ground truth (\ref{eq:dice_loss}), effectively capturing the regions of interest despite their limited size.
\vskip1em
In contrast, cross-entropy loss measures the dissimilarity between the predicted probability distribution and the true distribution (\ref{eq:ce_loss}). While it is easier to optimize due to its differentiable nature, cross-entropy can be more sensitive to class imbalances. This sensitivity may lead to suboptimal performance when the class of interest (e.g., tumors) constitutes only a small fraction of the total data.
\vskip1em
Given these characteristics, a hybrid approach that combines both Dice loss and cross-entropy loss offers a promising solution. This combination leverages the strengths of both methods: Dice loss ensures that the model pays adequate attention to the small tumor regions, while cross-entropy facilitates stable and efficient optimization. Such an approach can yield improved segmentation performance, making it particularly suitable for complex tasks in medical imaging.
\newpage
To enhance training performance, mixed precision training utilizing PyTorch has been implemented. This approach leverages both single-precision (32-bit) and half-precision (16-bit) floating-point formats during model training. By employing mixed precision, the training speed is significantly increased due to reduced computational overhead, while the memory footprint is minimized. This allows for the efficient use of hardware resources, facilitating larger batch sizes and improved model scalability without compromising numerical stability.
The training run on a TODO with around 30Go of memory use.
\vskip1em
Prior to training, additional preprocessing steps were applied to the images. Specifically, the CT images were min-max normalized to a range of 0 to 1, ensuring consistent scaling across the dataset. In contrast, PET images were normalized to have a zero mean, adjusting for intensity variations while preserving the relative distribution of values.
\vskip1em
These normalization procedures were performed dynamically during the training phase, allowing the images to be stored in their original format in NIfTI files. This preserved the integrity of the original data, enabling direct computation of properties from the segmented regions in subsequent analyses.
\vskip1em
To enhance model performance, the training dataset has been partitioned into five folds representing ~90\% (with ~80\% for training and ~20\% for validation) of the initial 524 cases, facilitating a cross-validation approach. This technique allows for the integration of predictions from each fold, thereby improving the consistency and robustness of the model's predictions. By leveraging multiple subsets of the data during training, the model can better generalize to unseen data, ultimately leading to more reliable and stable results. This method not only mitigates overfitting but also enhances the overall accuracy of the predictions.
\vskip1em
For the validation process, as outlined in the data augmentation section, a single patch was selected, ensuring equal distribution across the channels. This approach generates a validation set that is representative of the entire image while significantly reducing computational time. The validation set comprised 20% of the training data, which was passed through the model to estimate the probability of tumor presence.
\vskip1em
Following model inference, a postprocessing step was applied to the softmax output. This involved converting the probabilistic output into a binary mask by applying a threshold of 0.5, where values greater than or equal to 0.5 were classified as positive for the presence of a tumor, and values below this threshold were classified as negative.
\subsection{Inference}
During the inference phase, the test set comprised 50 cases, constituting approximately 10\% of the original dataset. Each case was subjected to 37 inference passes, which included 6 distinct perturbations applied at 3 different levels of severity for each of the two modalities, as well as one baseline inference without any perturbation. Detailed descriptions of these perturbations and their respective parameters are provided in the Analysis section.
\vskip1em
The inference results yielded 37 segmented binary masks for each of the 50 cases, representing the model's predictions under different conditions. These binary masks were used for subsequent analysis to assess the consistency and robustness of the model's segmentation performance across different perturbation scenarios.

\section{Analysis}
\subsection{Robustness}

As outlined in the Inference section, six perturbations were applied to the data to assess the robustness of the model 
against variations that may be encountered in real-world scenarios, such as sensor noise or image artifacts. These perturbations, derived from the torchio library, simulate various types of distortions and alterations that may impact model performance.
 The six perturbations are described below :
\begin{itemize}
    \setlength\itemsep{1pt}
    \setlength\parskip{0pt}
    \setlength\topsep{0pt}
    \item \textbf{Noise}: Random variations in pixel intensity, simulating the effect of sensor or environmental noise during image acquisition.
    \item \textbf{Motion}: Simulates patient movement during the scan, leading to blurring or streaking in the images.
    \item \textbf{Blur}: Reduces image sharpness, simulating out-of-focus images or lower resolution captures.
    \item \textbf{Spike}: Alternating bright and dark lines in the image, simulating sensor errors or environmental interference during the scan.
    \item \textbf{Bias}: Intensity shifts or gradients across the image, simulating uneven lighting or sensor sensitivity changes.
    \item \textbf{Ghosting}: Artifacts that simulate image echoes or multiple exposures due to acquisition errors, causing repeated structures in the image.
\end{itemize}

\noindent Here is a visual representation of the perturbations applied :

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{images/perturbations.PNG}
    \caption{Perturbations}
    \label{fig:three_subfigures}
\end{figure}


Each perturbation was applied independently to either the CT or PET modality at three varying degrees of severity: 
low, medium, and high. These severity levels correspond to increasing intensities of the perturbation, where low 
severity represents minimal distortion and high severity introduces significant alterations to the image. The figure 
above illustrates the perturbations at each severity level for the CT modality.

Note that the noise perturbations may not be accurately represented here; however, more detailed visualizations and discussion 
of the noise effects on the images are provided in the Results section.
\vskip1em
To assess the impact of perturbations on segmentation performance, we utilized evaluation metrics from the Pymia library. 
The metrics employed are as follows:
\begin{itemize} 
    \setlength\itemsep{1pt} 
    \setlength\parskip{0pt} 
    \setlength\topsep{0pt} 
    \item \textbf{Dice coefficient}: A similarity index that measures the overlap between predicted and ground truth segmentation. 
    \item \textbf{Hausdorff distance}: A metric that evaluates the maximum boundary distance between predicted and ground truth segmentation contours. 
    \item \textbf{Jaccard index}: A measure of overlap between predicted and true segmentation, similar to the Dice coefficient but more sensitive to boundary errors. 
    \item \textbf{Sensitivity}: Measures the proportion of true positives correctly identified by the model. 
    \item \textbf{Specificity}: Measures the proportion of true negatives correctly identified by the model. 
    \item \textbf{Accuracy}: Evaluates the overall performance of the model by considering both true positives and true negatives. 
\end{itemize}

To analyze the impact of each perturbation, the delta for each evaluation metric was computed by calculating the difference between the baseline (unperturbed) metric and the corresponding metric obtained after applying the perturbation. This delta value quantifies the performance change induced by each perturbation, providing insight into how robust the model is under varying conditions.
\vskip1em
For each of the six perturbations, delta values were computed for all three severity levels, separately for both the CT and PET modalities. Boxplots were generated to visualize the distribution of these delta values across all test cases. The boxplots represent the central tendency (median) and variability (interquartile range) of the delta values for each metric, with whiskers extending to the most extreme non-outlier values. Outliers were identified to highlight cases where perturbations had an unusually large effect on model performance.
\vskip1em
This analysis enables a detailed comparison of the model’s robustness to different perturbations and degrees of severity for both imaging modalities. Further interpretation of these results is discussed in the Results section.
\newpage

In addition to the computation of the previously described metrics, we computed properties of the segmented area to 
investigate potential correlations between the change in Dice coefficient induced by perturbations and these properties. 
For example, we examined whether the volume of the segmented area correlates with greater changes in perturbed images due 
to motion. The properties are as follows:
\begin{itemize}
    \setlength\itemsep{1pt} 
    \setlength\parskip{0pt} 
    \setlength\topsep{0pt} 
    \item \textbf{Volume}: Total number of voxels belonging to the region of interest, computed as the sum of all `True` values in the ground truth boolean mask.
    \item \textbf{Surface Area}: The area of the surface boundary of the region, computed using compactness and surface area algorithms on the labeled region.
    \item \textbf{Compactness}: A shape descriptor that relates the surface area to the volume, indicating how compact or spread out the region is. (Maximum value of 1 corresponds to a perfect sphere.)
    \item \textbf{Distance from Center}: Euclidean distance from the center of mass (centroid) of the region to the center of the entire image.
    \item \textbf{Boundary Length}: Length of the boundary of the region, calculated using the Sobel operator on the ground truth mask.
    \item \textbf{CT Intensity Variability}: The standard deviation of the intensity values in the CT image for the region of interest, measuring intensity variation within the region.
    \item \textbf{PET Intensity Variability}: The standard deviation of intensity values in the PET image for the region of interest, representing variability in PET signal.
    \item \textbf{CT F/B Contrast}: Contrast between the mean intensity in the foreground (region of interest) and the background in the CT image, calculated as the difference between the mean intensities.
    \item \textbf{PET F/B Contrast}: Contrast between the mean intensity in the foreground and background in the PET image, computed similarly to the CT contrast.
    \item \textbf{SUVmax}: The maximum standardized uptake value (SUV) in the PET image within the region, indicating the highest metabolic activity.
    \item \textbf{CT Number (HU)}: The mean Hounsfield unit (HU) value within the region of interest in the CT image.
    \item \textbf{PET Number}: The mean standardized uptake value (SUV) within the region of interest in the PET image.
    \item \textbf{Regions}: The number of regions in the labeled ground truth, representing distinct anatomical regions.
    \item \textbf{Entropy}: A measure of the randomness or complexity of the region, reflecting the degree of heterogeneity in the image data.
\end{itemize}

Scatter plots of each perturbation at varying degrees were generated against each of the properties listed above. 
The goal is to determine whether perturbations have a more significant effect on specific cases, such as certain anatomical 
regions or volume sizes. Statistical correlations were computed using Pearson, Spearman and Kendall methods to assess 
these relationships.

\newpage
\subsection{Clinical evaluation}
To assess the relevance of geometrical metrics used in deep learning, we conducted a clinical evaluation of 50 test cases in collaboration with a 
physician specializing in head and neck radiation oncology. The evaluation utilized a 5-point Likert scale for grading. 
The representations of the 5-point grades are provided below:

\begin{itemize}
    \setlength\itemsep{1pt} 
    \setlength\parskip{0pt} 
    \setlength\topsep{0pt} 
    \item \textbf{\ding{73}}: Unable to utilize the prediction; necessitates complete reconstruction.
    \item \textbf{\ding{73}\ding{73}}: Able to utilize the prediction but requires significant modifications.
    \item \textbf{\ding{73}\ding{73}\ding{73}}: Able to utilize the prediction with some modifications.
    \item \textbf{\ding{73}\ding{73}\ding{73}\ding{73}}: Able to utilize the prediction with minor modifications.
    \item \textbf{\ding{73}\ding{73}\ding{73}\ding{73}\ding{73}}: Able to utilize the prediction in its original form.
\end{itemize}
The objective of this evaluation is to provide a comprehensive assessment of the model's performance and to quantify the correlation between the geometrical metrics and physician expertise. The evaluation was conducted specifically for each label, including Primary and Nodal tumors. 
Subsequently, scatter plots were generated to visualize the relationships between the various geometrical metrics, including the Dice score, Hausdorff distance, and Jaccard index. The correlations between these metrics and the physician evaluations were computed using Pearson correlation coefficients.
\vskip1em
The 50 cases were categorized into two groups: one consisting of baseline images (without perturbations), representing 32 images, and the other comprising perturbed images influenced by the three most significant perturbations. For each perturbation and modality, three cases were selected, resulting in a total of six cases for each of the three perturbations, accounting for the final 18 cases.
\vskip1em
This approach allows us to analyze the impact of perturbations on real-case evaluations and to assess whether there is a correlation with the effects represented by the delta Dice score. 
\vskip1em
This analysis, enables us to evaluate the relevance of the geometrical metrics in predicting clinical outcomes. 
The findings will contribute to understanding the robustness of the model, its practical applicability in clinical settings, 
and the significance of geometrical metrics in enhancing model performance and decision-making in radiotherapy.
Limitations of this study include potential biases arising from the subjective nature of physician evaluations, as the assessment was conducted by a single observer. 


\endinput